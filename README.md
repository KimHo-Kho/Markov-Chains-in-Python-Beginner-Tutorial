# Markov-Chains-in-Python-Beginner-Tutorial
https://www.datacamp.com/tutorial/markov-chains-python-tutorial


Learn about Markov Chains, their properties, transition matrices, and implement one yourself in Python!
A Markov chain is a mathematical system usually defined as a collection of random variables, that transition from one state to another according to certain probabilistic rules. These set of transition satisfies the Markov Property, which states that the probability of transitioning to any particular state is dependent solely on the current state and time elapsed, and not on the sequence of state that preceded it. This unique characteristic of Markov processes render them memoryless.

In this tutorial, you will discover when you can use markov chains, what the Discrete Time Markov chain is. You'll also learn about the components that are needed to build a (Discrete-time) Markov chain model and some of its common properties. Next, you'll implement one such simple model with Python using its numpy and random libraries. You will also learn some of the ways to represent a Markov chain like a state diagram and transition matrix.
Want to tackle more statistics topics with Python? Check out DataCamp's Statistical Thinking in Python course!

Let's transition...
